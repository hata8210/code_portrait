{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入依赖包\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from nltk import word_tokenize\n",
    "# 导入自定义依赖包\n",
    "import LoadFileDemo as lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.定义分词符号集合和目标分词符号\n",
    "sepatate_symbol = ['\\r\\n','\\r','\\n','\\t',' ','_','.',',','+'\n",
    "                   ,'-','=',';',':','/','*','#','@','?','!'\n",
    "                   ,'%','^',\"'\",'\"','(',')','[',']','{','}','&','~','|','-']\n",
    "target_symbol = ' '\n",
    "\n",
    "# 2.分词符号分词方法\n",
    "def sepatate_by_symbol(text = '',sepatate_symbol = [' ']):\n",
    "    # 1.循环匹配分词符号集合sepatate_symbol,替换成目标分词符号target_symbol\n",
    "    for symbol in sepatate_symbol:\n",
    "        text = text.replace(symbol, target_symbol)\n",
    "    #print('分词符号替换后效果:  %s ' % text)\n",
    "    return text\n",
    "\n",
    "# 3.分词符号分词方法\n",
    "def sepatate_by_case(text = ''):\n",
    "    # 1.遍历text字符（可使用集合序列化操作或map方法）\n",
    "    text_list = list(text)\n",
    "    for i in range(len(text_list)):\n",
    "        if i==0 : continue\n",
    "        # 判断是数字则用分词符号替换\n",
    "        if text_list[i].isdigit():\n",
    "            text_list[i] = target_symbol\n",
    "        # 判断符合驼峰命名的插入分词符号分词\n",
    "        if text_list[i-1].isalpha() and text_list[i].isalpha():\n",
    "            if text_list[i-1] == text_list[i-1].lower() and text_list[i] == text_list[i].upper():\n",
    "                text_list.insert(i,target_symbol)\n",
    "    rs =  \"\".join(text_list)   \n",
    "    #print('驼峰命名替换后效果:  %s ' % rs)\n",
    "    return rs\n",
    "\n",
    "# 4.输入文本进行分词\n",
    "def separate_text_single(text = ''):\n",
    "    # 加入目标分词符号\n",
    "    print(\"分词符号集合: %s \" % sepatate_symbol)\n",
    "    print(\"目标分词符号: %s \" % target_symbol)\n",
    "    text_pro = sepatate_by_case(sepatate_by_symbol(text, sepatate_symbol))\n",
    "    # 使用word_tokenize分词\n",
    "    rs = word_tokenize(text_pro)\n",
    "    return rs\n",
    "\n",
    "def separate_texts(text_list = ['']):\n",
    "    # 遍历每篇文章\n",
    "    return [separate_text_single(text) for text in text_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------初始化-------------------\n",
      "导入的数据集是： /Users/hata/Develop/workspace_python/jupyter-notebook/CodePortrait/data/books \n",
      "------------------测试加载样本数据-------------------\n",
      "输入目录地址：/Users/hata/Develop/workspace_python/jupyter-notebook/CodePortrait/data/books\n",
      "－－－－－－－－－－－\n",
      "当前目录地址：/Users/hata/Develop/workspace_python/jupyter-notebook/CodePortrait/data/books\n",
      "含有文件：['.DS_Store', '2400 2.txt', '2400.txt']\n",
      "－－－－－－－－－－－\n",
      "当前目录地址：/Users/hata/Develop/workspace_python/jupyter-notebook/CodePortrait/data/books/burton\n",
      "含有文件：['.DS_Store', '18506.txt', '2400.txt', '4657.txt', '4658.txt', '5760.txt', '5761.txt', '6036.txt', '6886.txt', '7111.txt', '7113.txt', '8821.txt']\n",
      "－－－－－－－－－－－\n",
      "当前目录地址：/Users/hata/Develop/workspace_python/jupyter-notebook/CodePortrait/data/books/burton/sub\n",
      "含有文件：['.DS_Store', '2400.txt']\n",
      "－－－－－－－－－－－\n",
      "当前目录地址：/Users/hata/Develop/workspace_python/jupyter-notebook/CodePortrait/data/books/burton/sub/sub\n",
      "含有文件：['2400.txt']\n",
      "－－－－－－－－－－－\n",
      "当前目录地址：/Users/hata/Develop/workspace_python/jupyter-notebook/CodePortrait/data/books/test\n",
      "含有文件：['2400.txt']\n",
      "------------------检查加载样本数据-------------------\n",
      "documents length: 16 \n",
      "filenames length: 16 \n",
      "paths length: 16 \n"
     ]
    }
   ],
   "source": [
    "lf.log('初始化')\n",
    "path_folder = '/Users/hata/Develop/' \\\n",
    "    + 'workspace_python/jupyter-notebook/' \\\n",
    "    + 'CodePortrait/data/'\n",
    "data_folder=os.path.join(path_folder,\"books\")\n",
    "print('导入的数据集是： %s ' % data_folder)\n",
    "\n",
    "lf.log('测试加载样本数据')\n",
    "documents, filenames, paths = lf.load_project_data(data_folder)\n",
    "lf.log('检查加载样本数据')\n",
    "print('documents length: %i ' % len(documents))\n",
    "print('filenames length: %i ' % len(filenames))\n",
    "print('paths length: %i ' % len(paths))\n",
    "\n",
    "#print(paths[:1])\n",
    "#print(filenames[:1])\n",
    "#print(documents[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------测试分词效果（单篇）-------------------\n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "------------------输入-------------------\n",
      "\n",
      "Produced ； b\ty Sa8ra Vazirian\n",
      "\n",
      "\n",
      "VikRam\n",
      "------------------输出-------------------\n",
      "['Produced', '；', 'b', 'y', 'Sa', 'ra', 'Vazirian', 'Vik', 'Ram']\n"
     ]
    }
   ],
   "source": [
    "lf.log('测试分词效果（单篇）')\n",
    "input_text = '\\nProduced ； b\\ty Sa8ra Vazirian\\n\\n\\nVikRam'\n",
    "output_text = separate_text_single(input_text)\n",
    "lf.log('输入')\n",
    "print(input_text)\n",
    "lf.log('输出')\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------测试分词效果（全部）-------------------\n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "分词符号集合: ['\\r\\n', '\\r', '\\n', '\\t', ' ', '_', '.', ',', '+', '-', '=', ';', ':', '/', '*', '#', '@', '?', '!', '%', '^', \"'\", '\"', '(', ')', '[', ']', '{', '}', '&', '~', '|', '-'] \n",
      "目标分词符号:   \n",
      "------------------输出-------------------\n",
      "output_texts length: 16 \n"
     ]
    }
   ],
   "source": [
    "lf.log('测试分词效果（全部）')\n",
    "output_texts = separate_texts(documents)\n",
    "lf.log('输出')\n",
    "print('output_texts length: %i ' % len(output_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
